---
layout: post
title: æœºå™¨å­¦ä¹ -ç™½æ¿æ¨å¯¼ç³»åˆ—ï¼ˆä¸€ï¼‰
date: 2019-08-16 17:00:00
author: "chenjing"
header-img: "img/post-bg-universe.jpg"
catalog: false
mathjax: true
tags:
  - æœºå™¨å­¦ä¹ 
  - å…¬å¼æ¨å¯¼
---

# ç»ªè®º

å†å¼€ä¸€ä¸ªå‘ã€‚

å‰æ®µæ—¶é—´çªç„¶æƒ³å·©å›ºæœºå™¨å­¦ä¹ çš„ç›¸å…³å†…å®¹ï¼Œå¹¸è€Œåœ¨bç«™çœ‹åˆ°ä¸€ä½å¤§ä½¬çš„[ã€Šæœºå™¨å­¦ä¹ -ç™½æ¿æ¨å¯¼ã€‹ç³»åˆ—è¯¾ç¨‹](https://space.bilibili.com/97068901/video)ï¼ŒèŠ±äº†å¤§æ¦‚20å¤©å·¦å³æŠŠè¯¾ç¨‹å¬å®Œäº†ã€‚è¿™ä¸ªç³»åˆ—çš„è¯¾ç¨‹å¯¹ â€œå°ç™½â€ï¼ˆå­¦è¿‡çº¿æ€§ä»£æ•°ã€æ¦‚ç‡è®ºä»¥åŠå¾®ç§¯åˆ†ï¼‰éå¸¸å‹å¥½ï¼Œå› ä¸ºä½ é¢å¯¹çš„ä¸æ˜¯æ¯ç‡¥çš„ã€æ»¡æ˜¯å…¬å¼çš„ä¸“ä¸šæ•™æï¼Œè€Œæ˜¯ä¸€ä¸ªæ„¿æ„èŠ±æ—¶é—´åšå‡ºç»†è‡´ä¸”å½¢è±¡çš„è§£é‡Šçš„å¤§ä½¬ğŸ˜ï¼Œè€Œä¸”å¤§ä½¬ä¸€æ­¥ä¸€æ­¥éå¸¸æ¸…æ™°åœ° çº¯ Â· æ‰‹æ¨å…¬å¼ï¼Œå¤§ä½¬è¯·å—æˆ‘ä¸€æ‹œã€‚å¤§ä½¬åœ¨è®²ä¸€ä¸ªæ¨¡å‹æ—¶ä¼šå¼•ç”³å‡ºå¾ˆå¤šæ¨¡å‹å’Œç®—æ³•ï¼Œå¹¶æ‰¾å‡ºä»–ä»¬çš„ç›¸åŒç‚¹å’Œä¸åŒç‚¹ï¼Œåˆ°åæ¥ä½ ä¼šå‘ç°å¾ˆå¤šæ¨¡å‹éƒ½æœ‰å†…åœ¨çš„è”ç³»ï¼Œè±ç„¶å¼€æœ—ï¼Œè¶Šå¬è¶Šæœ‰å‘³ï¼Œä¸€å¤©ä¸å¬æµ‘èº«å‘ç—’ã€‚ã€‚ã€‚å¸Œæœ›ä½ ä¹Ÿæœ‰è¿™æ ·çš„ä½“ä¼šğŸ˜¬

å¥½äº†ï¼Œå¼€è¿™ä¸ªç³»åˆ—æ˜¯ä¸ºäº†ä¿å­˜ç¬”è®°ï¼Œå…¶é—´å¯èƒ½ä¼šåŠ ä¸€äº›è‡ªå·±å¯¹æ¨¡å‹æˆ–ç®—æ³•çš„ç†è§£ï¼Œä½†å¤§éƒ¨åˆ†ä»¥å¤§ä½¬çš„ä¸ºä¸»ã€‚

ä¸€å¼€å§‹ï¼Œä»‹ç»äº†æœºå™¨å­¦ä¹ çš„ä¸¤ä¸ªæ´¾åˆ«ï¼Œ**é¢‘ç‡æ´¾**å’Œ**è´å¶æ–¯æ´¾**ï¼Œé¢‘ç‡æ´¾æ¸æ¸å‘å±•å‡ºäº†**ç»Ÿè®¡æœºå™¨å­¦ä¹ **ï¼Œè´å¶æ–¯æ´¾æ¸æ¸å‘å±•å‡ºäº†**æ¦‚ç‡å›¾æ¨¡å‹**ã€‚

### å‚è€ƒä¹¦ç±ï¼š

æèˆªçš„ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ã€å‘¨å¿—åçš„ã€Šæœºå™¨å­¦ä¹ ã€‹ï¼ˆè¥¿ç“œä¹¦ï¼‰ã€ã€ŠDeep Learningã€‹ï¼ˆèŠ±ä¹¦ï¼‰ï¼Œä»¥åŠæœºå™¨å­¦ä¹ ä¸‰å¤§ç¥ä¹¦ã€ŠPattern Recognition and Machine Learningã€‹ï¼ˆPRMLï¼‰ã€ã€ŠMachine Learning : A Probabilistic Perspectiveã€‹ï¼ˆMLAPPï¼‰ã€ã€ŠThe Elements of Statistical Learningã€‹ï¼ˆESLï¼‰ã€‚å…¶ä¸­ï¼Œæèˆªçš„ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹å’Œã€ŠESLã€‹å±äºé¢‘ç‡æ´¾ï¼›ã€ŠPRMLã€‹å±äºè´å¶æ–¯æ´¾ï¼›ã€ŠMLAPPã€‹æœ‰ç‚¹åƒã€ŠPRMLã€‹å’Œã€ŠESLã€‹çš„ç»“åˆä½“ï¼Œæ˜¯ç™¾ç§‘å…¨ä¹¦æ€§è´¨çš„ä¹¦ï¼Œä½†ä¸»è¦ä»¥è´å¶æ–¯çš„è§’åº¦æ¥å†™ï¼›å‘¨å¿—åçš„æœºå™¨å­¦ä¹ æ›´åƒæ˜¯ä¸€æœ¬æ‰‹å†Œï¼Œæ²¡æœ‰æ·±å…¥çš„å…¬å¼æ¨å¯¼ï¼Œä½†ä»‹ç»çš„å¾ˆå…¨é¢ï¼›ã€ŠDeep Learningã€‹å°±æ˜¯å¤§åé¼é¼çš„èŠ±ä¹¦äº†ï¼Œçœ‹ä¹¦åå°±çŸ¥é“æ˜¯è®²æ·±åº¦å­¦ä¹ çš„ã€‚

> æèˆªçš„ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ä¸­è®²äº†10ä¸ªç®—æ³•ï¼Œç”¨ä¸€å¥å£è¯€æ¥è®°ï¼šæ„ŸKæœ´å†³é€»ï¼Œæ”¯æEéšæ¡ã€‚ã€ŠPRMLã€‹çš„ä¸»è¦å†…å®¹ä¹Ÿå¯æ€»ç»“ä¸ºä¸€å¥å£è¯€ï¼šå›åˆ†ç¥æ ¸ç¨€ï¼Œå›¾æ··è¿‘é‡‡è¿ï¼Œé¡ºç»„ã€‚

### è§†é¢‘èµ„æ–™ï¼š

1  å°æ¹¾å¤§å­¦æ—è½©ç”°çš„ã€Šæœºå™¨å­¦ä¹ åŸºçŸ³ã€‹ï¼šVC Theoryã€æ­£åˆ™åŒ–ã€çº¿æ€§æ¨¡å‹ç­‰ï¼›ã€Šæœºå™¨å­¦ä¹ æŠ€æ³•ã€‹ï¼šSVMã€å†³ç­–æ ‘ã€éšæœºæ£®æ—ã€ç¥ç»ç½‘ç»œç­‰ã€‚

2  å¼ å¿—åçš„ã€Šæœºå™¨å­¦ä¹ å¯¼è®ºã€‹ï¼šä¸»è¦æ˜¯ä»¥é¢‘ç‡æ´¾çš„è§’åº¦é˜è¿°ï¼›ã€Šç»Ÿè®¡æœºå™¨å­¦ä¹ ã€‹ï¼šä¸»è¦è®²ç»Ÿè®¡ä¸Šçš„ä¸€äº›ç†è®ºï¼Œä»¥è´å¶æ–¯çš„è§’åº¦é˜è¿°ï¼Œåæ•°å­¦æ–¹é¢ã€‚è¿™ä¸¤é—¨è¯¾æ˜¯å¼ å¿—åè€å¸ˆåœ¨ä¸Šæµ·äº¤é€šå¤§å­¦æ—¶å¼€çš„ï¼Œç°åœ¨å¼ å¿—åè€å¸ˆå·²ç»å»äº†åŒ—å¤§ã€‚

3  æ–¯å¦ç¦å¤§å­¦ Andrew Ngï¼ˆå´æ©è¾¾ï¼‰: Stanford CS229 2017ï¼Œéå¸¸æœ‰åï¼Œä¸ä»‹ç»äº†ã€‚

4  æ‚‰å°¼ç§‘æŠ€å¤§å­¦å¾äº¦è¾¾çš„ã€Šæœºå™¨å­¦ä¹ ã€‹ï¼šé˜è¿°ä¸€äº›åˆ—æ¦‚ç‡æ¨¡å‹ï¼ŒEMã€MCMCã€Calman Filterï¼Œç²’å­æ»¤æ³¢ï¼Œç‹„åˆ©å…‹é›·è¿‡ç¨‹ã€‚GitHubä¸Šæœ‰ç¬”è®°ï¼Œå¾ˆå…¨ï¼

5  å°æ¹¾å¤§å­¦æå®æ¯…çš„ã€Šæœºå™¨å­¦ä¹ ã€‹ï¼šCNNã€DNNï¼›ã€ŠMLDSã€‹ï¼šä¼˜åŒ–ã€æ­£åˆ™åŒ–ã€å®è·µä¼˜åŒ–ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰ã€‚

### ç¬¦å·çº¦å®š

æˆ‘ä»¬å…ˆè§„å®šä¸€äº›ç¬¦å·ï¼š$\mathbf{X}$ è¡¨ç¤ºæ•°æ®ï¼ˆdataï¼‰ï¼Œæ˜¯ä¸€ä¸ªæ ·æœ¬çŸ©é˜µï¼Œæ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªæ ·æœ¬ï¼ˆéšæœºå˜é‡ï¼‰ï¼Œ$\theta$ è¡¨ç¤ºå‚æ•°ï¼ˆparameterï¼‰ï¼Œå¤šæ•°æƒ…å†µä¸‹æ˜¯ä¸€ä¸ªå‘é‡ã€‚

$$\mathbf{X}=(X_1\ X_2\ \cdots \ X_N)^{\mathrm{T}}=\begin{pmatrix} X_1^{\mathrm{T}}\\ X_2^{\mathrm{T}} \\ \vdots \\ X_N^{\mathrm{T}} \\ \end{pmatrix}\\ = \begin{pmatrix} x_{11} & x_{12} & \cdots &x_{1p}\\ x_{21} & x_{22} & \cdots &x_{2p}\\ \vdots & \vdots & \ddots & \vdots \\ x_{N1}& x_{N2} & \cdots & x_{Np} \\ \end{pmatrix}\\$$ 

å…¶ä¸­ï¼Œ$\mathbf{X} \in \mathbb{R}^{ N \times p}$ï¼Œ $X_i \in \mathbb{R}^{ p \times 1}, i = 1,2,\cdots,N$ã€‚æˆ‘ä»¬ç”¨å¤§å†™ç²—ä½“çš„ $\mathbf{X}$ è¡¨ç¤ºç”± $N$ ä¸ªéšæœºå˜é‡ç»„æˆçš„çŸ©é˜µï¼Œç”¨ å¤§å†™ç»†ä½“çš„ $X$ è¡¨ç¤ºéšæœºå˜é‡ï¼Œç”¨å°å†™ç»†ä½“çš„ $x$ è¡¨ç¤ºéšæœºå˜é‡çš„å…·ä½“å–å€¼ã€‚

è‹¥ $X$ æœä»äºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œè®°ä¸º $ X\sim P(X \mid \theta)$ï¼Œè¿™é‡Œæˆ‘ä»¬ç”¨å¤§å†™çš„ $P(Â·)$ è¡¨ç¤ºæ¦‚ç‡åˆ†å¸ƒï¼Œç”¨å°å†™çš„ $p(Â·)$ è¡¨ç¤ºæ¦‚ç‡å¯†åº¦å‡½æ•°æˆ–ç¦»æ•£åˆ†å¸ƒå¾‹ã€‚æ­¤å¤„ï¼Œå½“ $\theta$ ä¸ºå‚æ•°æ—¶ï¼Œ ä»¥ä¸‹ä¸¤ç§è¡¨ç¤ºæ–¹å¼ç­‰ä»·ï¼š $P(X \mid \theta) \iff P(X;\theta)$ ã€‚ä»Šåè‹¥ä¸ç‰¹æ®Šè¯´æ˜ï¼Œæˆ‘ä»¬éƒ½ç”¨å·¦ä¾§çš„è¡¨ç¤ºæ–¹å¼ã€‚

ä»Šåçš„ç¬¦å·éƒ½ä¾ç…§ä»¥ä¸Šè§„åˆ™ã€‚

### é¢‘ç‡æ´¾ VS è´å¶æ–¯æ´¾

#### é¢‘ç‡æ´¾

$\theta$ ä¸ºæœªçŸ¥å¸¸é‡ï¼Œ$X$ ä¸ºéšæœºå˜é‡ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬è¦ä¼°è®¡çš„æ˜¯ $\theta$ã€‚æœ€å¸¸ç”¨çš„æ–¹æ³•æ˜¯æå¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMaximum Likelihood Estimationï¼‰ï¼Œ

$$\theta_{MLE}=\underset{\theta}{\operatorname{argmax}}\; \log  \underbrace{P(X \mid \theta)}_{L(\theta)}$$ 

$L(\theta)$ æ˜¯ä¼¼ç„¶å‡½æ•°ï¼Œ$L(\theta)=P(X \mid \theta)=\prod_{i=1}^N p(x_i \mid \theta) $ï¼Œ åŠ  $\log$ æ˜¯ä¸ºäº†ç®€åŒ–è¿ç®—ï¼Œåˆ©ç”¨å¯¹æ•°çš„è¿ç®—æ€§è´¨ï¼Œå°†è¿ä¹˜å˜ä¸ºè¿åŠ ï¼Œ$\prod \to \sum$ ï¼Œå³ $\log P(X \mid \theta)=\sum_{i=1}^N p(x_i \mid \theta)$ã€‚æˆ‘ä»¬çš„ç›®çš„æ˜¯æ±‚ä¸€ä¸ª $\hat{\theta}$ ä½¿å¾— $P(X \mid \hat{\theta})$ æœ€å¤§ã€‚

æ‰€ä»¥ï¼Œä»¥é¢‘ç‡æ´¾çš„è§†è§’ï¼Œæœ€ç»ˆè¦è§£å†³çš„æ˜¯**ä¼˜åŒ–é—®é¢˜**ã€‚

#### è´å¶æ–¯æ´¾

$\theta$ ä¸ºéšæœºå˜é‡ï¼Œ$\theta \sim p(\theta)$ï¼Œæ˜¯å…ˆéªŒæ¦‚ç‡åˆ†å¸ƒï¼ˆpriorï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æœ€ç»ˆè¦æ±‚çš„æ˜¯åéªŒæ¦‚ç‡ $P(\theta \mid X)$ï¼Œç”±è´å¶æ–¯å…¬å¼å¯å¾—ï¼š

$$P(\theta \mid X)= \dfrac{P(X \mid \theta)P(\theta)}{P(X)} \propto P(X \mid \theta)P(\theta)$$

å…¶ä¸­ï¼Œ$P(\theta \mid X)$ ä¸ºåéªŒæ¦‚ç‡ï¼ˆposteriorï¼‰ä¹Ÿå°±æ˜¯æˆ‘ä»¬è¦æ±‚çš„ï¼Œ$P(X \mid \theta)$ ä¸ºä¼¼ç„¶ï¼ˆlikelihoodï¼‰ï¼Œ$P(\theta)$ ä¸ºå…ˆéªŒï¼ˆpriorï¼‰ï¼Œ$P(X)$ æ˜¯ $P(X, \theta)$ çš„è¾¹ç¼˜åˆ†å¸ƒï¼Œä¾æ®è¾¹ç¼˜æ¦‚ç‡çš„æ±‚æ³•ï¼Œ $P(X)=\int_{\theta} {P(X \mid \theta)P(\theta)} \,{\rm d}\theta$ æ˜¯å¯ä»¥ç®—å‡ºæ¥çš„ï¼Œå¯ä»¥è®¤ä¸ºæ˜¯ä¸€ä¸ªå¸¸å€¼ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨æœ€å¤§åéªŒæ¦‚ç‡ï¼ˆMaximum  A  Posterioriï¼‰ï¼š

$$\theta_{MAP}=\underset{\theta}{\operatorname{argmax}}\; P(X \mid \theta)P(\theta)$$

**è´å¶æ–¯ä¼°è®¡ï¼š**

$$P(\theta \mid X)= \dfrac{P(X \mid \theta)P(\theta)}{\int_{\theta} {P(X \mid \theta)P(\theta)} \,{\rm d}\theta}$$

**è´å¶æ–¯é¢„æµ‹ï¼š**

å·²çŸ¥ $X$ï¼Œé¢„æµ‹ $\widetilde{X}$ï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡ $X$ å»é¢„æµ‹ $\theta$ï¼Œå†é€šè¿‡ $\theta$ é¢„æµ‹ $\widetilde{X}$ï¼Œå› æ­¤ï¼š

$$P(\widetilde{X} \mid X)=\int_{\theta} {P(\widetilde{X},\theta \mid X)} \,{\rm d}\theta =\int_{\theta} {P(\widetilde{X} \mid \theta) \underbrace{P(\theta \mid X)}_{posterior}} \,{\rm d}\theta$$

æ‰€ä»¥ï¼Œä»¥è´å¶æ–¯æ´¾çš„è§†è§’ï¼Œæœ€ç»ˆè¦è§£å†³çš„æ˜¯**æ±‚ç§¯åˆ†é—®é¢˜**ã€‚

---

